{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37909e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import keras\n",
    "import tensorflow\n",
    "import glob\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "#from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "#from tensorflow.keras.applications import VGG16\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "#                        初期設定部\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "# GrayScaleのときに1、COLORのときに3にする\n",
    "COLOR_CHANNEL = 3\n",
    "\n",
    "# 入力画像サイズ(画像サイズは正方形とする)\n",
    "INPUT_IMAGE_SIZE = 224\n",
    "\n",
    "# 訓練時のバッチサイズとエポック数\n",
    "BATCH_SIZE = 64\n",
    "EPOCH_NUM = 400\n",
    "\n",
    "# 使用する訓練画像の入ったフォルダ(ルート)\n",
    "TRAIN_PATH =  \n",
    "# 使用する訓練画像の各クラスのフォルダ名\n",
    "folder = [\"150\", \"170\", \"200\"]\n",
    "\n",
    "# CLASS数を取得する\n",
    "CLASS_NUM = len(folder)\n",
    "print(\"クラス数 : \" + str(CLASS_NUM))\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "#                        訓練画像入力部\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "# 各フォルダの画像を読み込む\n",
    "v_image = []\n",
    "v_label = []\n",
    "for folder_name in folder:\n",
    "    dir = os.path.join(TRAIN_PATH, folder_name)\n",
    "    files = glob.glob(os.path.join(dir, \"*.png\"))\n",
    "    print(dir)\n",
    "    for file in files:\n",
    "        if COLOR_CHANNEL == 1:\n",
    "            img = load_img(file, color_mode=\"grayscale\", target_size=(INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE))\n",
    "        elif COLOR_CHANNEL == 3:\n",
    "            img = load_img(file, color_mode=\"rgb\", target_size=(INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE))\n",
    "        array = img_to_array(img)\n",
    "        v_image.append(array)\n",
    "        v_label.append(int(folder_name))  # フォルダ名をラベルとして使用\n",
    "v_image = np.array(v_image)\n",
    "v_label = np.array(v_label)\n",
    "# ラベルの確認\n",
    "print(v_label)\n",
    "\n",
    "\n",
    "# imageの画素値をint型からfloat型にする\n",
    "v_image = v_image.astype('float32')\n",
    "# 画素値を[0～255]⇒[0～1]とする\n",
    "v_image = v_image / 255.0\n",
    "\n",
    "# データの前処理\n",
    "# ラベルを0から3の整数に変換\n",
    "#label_binarizer = LabelBinarizer()\n",
    "#v_label = label_binarizer.fit_transform(v_label)\n",
    "\n",
    "# 正解ラベルの形式を変換\n",
    "#v_label = np_utils.to_categorical(v_label, CLASS_NUM)\n",
    "\n",
    "# 学習用データと検証用データに分割する\n",
    "train_images, valid_images, train_labels, valid_labels = train_test_split(v_image, v_label, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faadbf25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "#VGG16\n",
    "input_shape=(224,224,3)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', input_shape=input_shape, name='block1_conv1'))\n",
    "model.add(BatchNormalization(name='bn1'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', name='block1_conv2'))\n",
    "model.add(BatchNormalization(name='bn2'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same', name='block1_pool'))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', name='block2_conv1'))\n",
    "model.add(BatchNormalization(name='bn3'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', name='block2_conv2'))\n",
    "model.add(BatchNormalization(name='bn4'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same', name='block2_pool'))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', name='block3_conv1'))\n",
    "model.add(BatchNormalization(name='bn5'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', name='block3_conv2'))\n",
    "model.add(BatchNormalization(name='bn6'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', name='block3_conv3'))\n",
    "model.add(BatchNormalization(name='bn7'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same', name='block3_pool'))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', name='block4_conv1'))\n",
    "model.add(BatchNormalization(name='bn8'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', name='block4_conv2'))\n",
    "model.add(BatchNormalization(name='bn9'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', name='block4_conv3'))\n",
    "model.add(BatchNormalization(name='bn10'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same', name='block4_pool'))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', name='block5_conv1'))\n",
    "model.add(BatchNormalization(name='bn11'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', name='block5_conv2'))\n",
    "model.add(BatchNormalization(name='bn12'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', name='block5_conv3'))\n",
    "model.add(BatchNormalization(name='bn13'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same', name='block5_pool'))\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dense(units=4096, activation='relu', name='fc1'))\n",
    "model.add(Dense(units=4096, activation='relu', name='fc2'))\n",
    "model.add(Dense(units=1, activation='linear', name='predictions'))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef482df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# モデルのコンパイル\n",
    "model.compile(optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])\n",
    "\n",
    "# 訓練中に損失とMAEを記録するためのリスト\n",
    "history = model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=EPOCH_NUM, validation_data=(valid_images, valid_labels))\n",
    "# 訓練中の損失とMAEの変化をプロット\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, mae, 'b', label='Training MAE')\n",
    "plt.plot(epochs, val_mae, 'r', label='Validation MAE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a430d94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "#                              訓練実行&結果確認部\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "# モデル構成の確認\n",
    "model.summary()\n",
    "\n",
    "score = model.evaluate(valid_images, valid_labels, verbose=0)\n",
    "print(len(valid_images))\n",
    "print('Loss:', score[0])\n",
    "print('Accuracy:', score[1])\n",
    "\n",
    "\n",
    "# 予測値と正解の散布図を作成\n",
    "y_pred = model.predict(valid_images)\n",
    "print(\"valid_labelsのデータ型:\", type(valid_labels[0]))\n",
    "print(\"y_predのデータ型:\", type(y_pred[0]))\n",
    "print(valid_labels)\n",
    "print(len(valid_labels))\n",
    "print(y_pred)\n",
    "print(len(y_pred))\n",
    "plt.scatter(valid_labels, y_pred)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('True Values vs. Predictions')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
