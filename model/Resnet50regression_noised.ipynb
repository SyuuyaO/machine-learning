{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747f6ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow\n",
    "import glob\n",
    "import pandas as pd\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "\n",
    "\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from tensorflow.keras.applications import VGG16\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Add, Input, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "#                        初期設定部\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Add, Input, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "def shortcut(conv, residual, stride, filters):\n",
    "    conv_shape = K.int_shape(conv)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    \n",
    "    # フィルタ数またはストライドが異なる場合、ショートカット経路で1x1の畳み込みを使用\n",
    "    if conv_shape != residual_shape:\n",
    "        residual = Conv2D(filters=filters, kernel_size=(1, 1), strides=(stride, stride), padding=\"same\")(residual)\n",
    "        residual = BatchNormalization()(residual)\n",
    "    return Add()([conv, residual])\n",
    "\n",
    "def bottleneck_res_block(x, filters, stride=1):\n",
    "    # Bottleneck architecture with three layers\n",
    "    conv = Conv2D(filters=filters, kernel_size=(1, 1), strides=(stride, stride), padding=\"same\", kernel_initializer='he_normal')(x)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "    \n",
    "    conv = Conv2D(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Activation(\"relu\")(conv)\n",
    "    \n",
    "    conv = Conv2D(filters=4*filters, kernel_size=(1, 1), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    \n",
    "    short_cut = shortcut(conv, x, stride, 4*filters)\n",
    "    conv = Activation(\"relu\")(short_cut)\n",
    "    return conv\n",
    "\n",
    "class ResNet50:\n",
    "    def __init__(self, input_shape, nb_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.nb_classes = nb_classes\n",
    "        self.model = self.make_model()\n",
    "\n",
    "    def make_model(self):\n",
    "        inputs = Input(self.input_shape)\n",
    "        x = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding=\"same\", kernel_initializer='he_normal')(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "        # ResNet50 layers: 3-4-6-3 structure with bottleneck blocks\n",
    "        x = bottleneck_res_block(x, 64)\n",
    "        x = bottleneck_res_block(x, 64)\n",
    "        x = bottleneck_res_block(x, 64)\n",
    "\n",
    "        x = bottleneck_res_block(x, 128, stride=2)\n",
    "        x = bottleneck_res_block(x, 128)\n",
    "        x = bottleneck_res_block(x, 128)\n",
    "        x = bottleneck_res_block(x, 128)\n",
    "\n",
    "        x = bottleneck_res_block(x, 256, stride=2)\n",
    "        x = bottleneck_res_block(x, 256)\n",
    "        x = bottleneck_res_block(x, 256)\n",
    "        x = bottleneck_res_block(x, 256)\n",
    "        x = bottleneck_res_block(x, 256)\n",
    "        x = bottleneck_res_block(x, 256)\n",
    "\n",
    "        x = bottleneck_res_block(x, 512, stride=2)\n",
    "        x = bottleneck_res_block(x, 512)\n",
    "        x = bottleneck_res_block(x, 512)\n",
    "\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        outputs = Dense(units=self.nb_classes, activation='linear')(x)\n",
    "        ResNetModel = Model(inputs=inputs, outputs=outputs)\n",
    "        return ResNetModel\n",
    "\n",
    "def build(input_shape, nb_classes):\n",
    "    return ResNet50(input_shape, nb_classes).model\n",
    "\n",
    "model = ResNet50(input_shape=(224,224,3), nb_classes=1).model\n",
    "\n",
    "# GrayScaleのときに1、COLORのときに3にする\n",
    "COLOR_CHANNEL = 3\n",
    "\n",
    "# 入力画像サイズ(画像サイズは正方形とする)\n",
    "INPUT_IMAGE_SIZE = 224\n",
    "\n",
    "# 訓練時のバッチサイズとエポック数\n",
    "BATCH_SIZE = 32\n",
    "EPOCH_NUM = 500\n",
    "\n",
    "# 使用する訓練画像の入ったフォルダ(ルート)\n",
    "TRAIN_PATH =  \"\"\n",
    "# 使用する訓練画像の各クラスのフォルダ名\n",
    "folder = [\"\"]\n",
    "\n",
    "\n",
    "# CLASS数を取得する\n",
    "CLASS_NUM = len(folder)\n",
    "print(\"クラス数 : \" + str(CLASS_NUM))\n",
    "\n",
    "#testを除いた中からvalidationの割合\n",
    "validation_rate = 0.2\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "   monitor='val_loss',\n",
    "   min_delta=0,\n",
    "   patience=100,\n",
    "   verbose=0,\n",
    "   mode='auto',\n",
    "   baseline=None,\n",
    "   restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# 分割数を設定\n",
    "k = 5\n",
    "\n",
    "#分割交差検証の平均算出用\n",
    "test_loss = [0]*k\n",
    "test_mae = [0]*k\n",
    "sum_mae = 0\n",
    "sum_val_mae = 0\n",
    "sum_test_mae = 0\n",
    "sum_loss = 0\n",
    "sum_val_loss = 0\n",
    "sum_test_loss = 0\n",
    "sum_r2 = 0\n",
    "\n",
    "    # 各フォルダの画像を読み込む\n",
    "v_image = []\n",
    "v_label = []\n",
    "for folder_name in folder:\n",
    "    dir = os.path.join(TRAIN_PATH, folder_name)\n",
    "    files = glob.glob(os.path.join(dir, \"*.png\"))\n",
    "    print(dir)\n",
    "    for file in files:\n",
    "        if COLOR_CHANNEL == 1:\n",
    "            img = load_img(file, color_mode=\"grayscale\", target_size=(INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE))\n",
    "        elif COLOR_CHANNEL == 3:\n",
    "            img = load_img(file, color_mode=\"rgb\", target_size=(INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE))\n",
    "        array = img_to_array(img)\n",
    "        v_image.append(array)\n",
    "        v_label.append(int(folder_name))  # フォルダ名をラベルとして使用\n",
    "v_image = np.array(v_image)\n",
    "v_label = np.array(v_label)\n",
    "\n",
    "# ラベルの確認\n",
    "print(v_label)\n",
    "\n",
    "\n",
    "# imageの画素値をint型からfloat型にする\n",
    "v_image = v_image.astype('float32')\n",
    "# 画素値を[0～255]⇒[0～1]とする\n",
    "v_image = v_image / 255.0\n",
    "\n",
    "# データの前処理\n",
    "# ラベルを0から3の整数に変換\n",
    "#label_binarizer = LabelBinarizer()\n",
    "#v_label = label_binarizer.fit_transform(v_label)\n",
    "\n",
    "# 正解ラベルの形式を変換\n",
    "#v_label = np_utils.to_categorical(v_label, CLASS_NUM)\n",
    "\n",
    "#正規化\n",
    "v_label = v_label.reshape(-1,1)\n",
    "scaler = MinMaxScaler()\n",
    "v_label = scaler.fit_transform(v_label)\n",
    "\n",
    "\n",
    "\n",
    "# ラベルの確認\n",
    "print(v_label)\n",
    "\n",
    "\n",
    "# 学習用データと検証用データに分割する\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "for fold_num, (train_index, test_index) in enumerate(kf.split(v_image)):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    print(f\"Fold {fold_num+1}:\")\n",
    "    # 訓練データとラベル\n",
    "    train_data, train_labels = v_image[train_index], v_label[train_index]\n",
    "\n",
    "    # テストデータとラベル\n",
    "    test_data, test_labels = v_image[test_index], v_label[test_index]\n",
    "    \n",
    "    # 訓練データのラベル分布 \n",
    "    train_label_counts = pd.Series(train_labels.ravel()).value_counts()\n",
    "    # テストデータのラベル分布 \n",
    "    test_label_counts = pd.Series(test_labels.ravel()).value_counts() \n",
    "    print(f\"Train label distribution:\\n{train_label_counts}\") \n",
    "    print(f\"Test label distribution:\\n{test_label_counts}\") \n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "\n",
    "    #labelbinarizer\n",
    "    #train_labels = label_binarizer.fit_transform(train_labels)\n",
    "    #test_labels = label_binarizer.fit_transform(test_labels)\n",
    "\n",
    "    #シャッフル\n",
    "    train_data, train_labels = shuffle(train_data, train_labels, random_state=0)\n",
    "\n",
    "    model = ResNet50(input_shape=(224,224,3), nb_classes=1).model\n",
    "\n",
    "    # モデルのコンパイル\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00005),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])\n",
    "\n",
    "    # 訓練中に損失とMAEを記録するためのリスト\n",
    "    history = model.fit(train_data, train_labels, validation_split = validation_rate, batch_size=BATCH_SIZE, epochs=EPOCH_NUM, callbacks = early_stopping)\n",
    "    # 訓練中の損失とMAEの変化をプロット\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    mae = history.history['mae']\n",
    "    val_mae = history.history['val_mae']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    #plt.yscale('log')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, mae, 'b', label='Training MAE')\n",
    "    plt.plot(epochs, val_mae, 'r', label='Validation MAE')\n",
    "    plt.title('Training and Validation MAE')\n",
    "    #plt.yscale('log')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    score = model.evaluate(test_data, test_labels, verbose=0)\n",
    "    print(len(test_data))\n",
    "    test_loss[fold_num]=score[0]\n",
    "    test_mae[fold_num]=score[1]\n",
    "    print('Loss:', score[0])\n",
    "    print('Mae:', score[1])\n",
    "\n",
    "    # 予測値と正解の散布図を作成\n",
    "    y_pred = model.predict(test_data)\n",
    "\n",
    "    sum_mae = sum_mae + mae[-1]\n",
    "    sum_val_mae = sum_val_mae + val_mae[-1]\n",
    "    sum_test_mae = sum_test_mae + score[1]\n",
    "    sum_loss = sum_loss + loss[-1]\n",
    "    sum_val_loss = sum_val_loss + val_loss[-1]\n",
    "    sum_test_loss = sum_test_loss + score[0]\n",
    "    sum_r2 = sum_r2 + r2_score(test_labels, y_pred)\n",
    "\n",
    "\n",
    "    # 1次元に変換する\n",
    "    #y_pred = y_pred.astype(np.int32)\n",
    "    #y_pred = y_pred.flatten()\n",
    "    #print(\"valid_labelsのデータ型:\", type(test_labels[0]))\n",
    "    #print(\"y_predのデータ型:\", type(y_pred[0]))\n",
    "    #print(test_labels)\n",
    "    #print(len(test_labels))\n",
    "    #print(y_pred)\n",
    "    #print(len(y_pred))\n",
    "\n",
    "    # 1次元に変換する\n",
    "    #y_pred = y_pred.flatten()\n",
    "    # 逆変換の例 \n",
    "    y_pred_scale = scaler.inverse_transform(y_pred)\n",
    "    test_labels_scale = scaler.inverse_transform(test_labels)\n",
    "    plt.scatter(test_labels_scale, y_pred_scale)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.title('True Values vs. Predictions')\n",
    "    plt.show()\n",
    "\n",
    "    #R2scoreの算出\n",
    "    print(f\"r2:{r2_score(test_labels, y_pred)}\")\n",
    "\n",
    "\n",
    "ave_mae = sum_mae/k\n",
    "ave_val_mae = sum_val_mae/k\n",
    "ave_test_mae = sum_test_mae/k\n",
    "ave_loss = sum_loss/k\n",
    "ave_val_loss = sum_val_loss/k\n",
    "ave_test_loss = sum_test_loss/k\n",
    "ave_r2 = sum_r2/k\n",
    "\n",
    "for j in range(k):\n",
    "    print(f\"hold{j+1}_test_loss:{test_loss[j]}\")\n",
    "\n",
    "\n",
    "for j in range(k):\n",
    "    print(f\"hold{j+1}_test_mae:{test_mae[j]}\")\n",
    "\n",
    "\n",
    "print(f\"平均mae: {ave_mae}\")\n",
    "print(f\"平均val_mae: {ave_val_mae}\")\n",
    "print(f\"平均test_mae: {ave_test_mae}\")\n",
    "print(f\"平均loss:{ave_loss}\")\n",
    "print(f\"平均val_loss:{ave_val_loss}\")\n",
    "print(f\"平均test_loss:{ave_test_loss}\")\n",
    "print(f\"平均r2:{ave_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b88a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
